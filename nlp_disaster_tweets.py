# -*- coding: utf-8 -*-
"""Nlp_disaster_tweets.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1690QnSkg6VnpBZq_CBW7bQyA1VMEw9Eu
"""

import pandas as pd
df=pd.read_csv('/content/train.csv')
df

df.drop(['id','keyword','location'],axis=1,inplace=True)
df

df.isna().sum()

import seaborn as sns
sns.countplot(x='target',data=df)

text=df.text
text

text=text.str.replace("[^a-zA-Z0-9 14]","",regex=True)
text

from nltk import SnowballStemmer
import nltk
stemmer=SnowballStemmer('english')

import nltk
nltk.download('punkt')

text=text.apply(lambda line:[stemmer.stem(word.lower()) for word in nltk.word_tokenize(line)]).apply(lambda token:" ".join(token))
text

from nltk.corpus import stopwords
nltk.download('stopwords')
sw=stopwords.words('english')

text=text.apply(lambda line:[stemmer.stem(word.lower()) for word in nltk.word_tokenize(line) if word not in sw]).apply(lambda token:" ".join(token))
text

from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer=TfidfVectorizer()
X=vectorizer.fit_transform(text)
X

print(X)

x=X.toarray()
x

df_new=pd.DataFrame(x)
df_new

y=df['target']
y

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=1)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report
knn=KNeighborsClassifier()
rfc=RandomForestClassifier()
abc=AdaBoostClassifier()
svc=SVC()

models=[knn,rfc,abc,svc]
for model in models:
    print(model)
    model.fit(X_train,y_train)
    y_new=model.predict(vectorizer.transform(['Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all']).toarray())
    print(y_new)
    y_pred=model.predict(X_test)
    print(classification_report(y_test,y_pred))